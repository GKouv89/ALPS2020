# Ανάπτυξη Λογισμικού για Πληροφοριακά Συστήματα 2020-21

Μέλη:

Γεωργία Κουτίβα, ΑΜ: 1115201700060
Αλέξανδρος Νεοφώτιστος, ΑΜ: 1115201700270

## Οι δομές μας και τι αντιπροσωπεύουν

* list_node: Αντιπροσωπεύει ένα αρχείο .json, με το id του (με την μορφή με την οποία εμφανίζεται στα .csv αρχεία), τα attribute/key pairs του, και κάποιους δείκτες που θα εξηγηθούν παρακάτω
* info_list: Μία λίστα από list_nodes. Υπάρχει μία τέτοια για κάθε bucket του hashmap μας. 
* node_tuple: Ένας κόμβος που περιέχει ένα attribute/key pair, μία γραμμή σε κάποιο αρχείο .json. Συνδέεται με τις υπόλοιπες γραμμές του εν λόγω αρχείου.
* tuplelist: Μία λίστα από node_tuples. Υπάρχει μία τέτοια για κάθε list_node.
* hash_map/hash_bucket: Υλοποίηση ενός τυπικού στατικού πίνακα κατακερματισμού. Κάθε bucket περιέχει μία λίστα των list_nodes των οποίων τα ids αντιστοιχούν σε αυτόν.
	* Η επιλογή της συνάρτησης κατακερματισμού, καθώς και του αριθμού των buckets, έγινε μετά από αναζήτηση στο διαδίκτυο, εφόσον αναφέρθηκε ότι επιτρέπεται.
		* Διαβάσαμε πως είναι καλό κάθε χαρακτήρας του string id να συνεισφέρει στο αποτέλεσμα της hash function, 
		* καθώς και πως ο πολλαπλασιασμός με πρώτο και η επιλογή πρώτου αριθμού για αριθμό buckets δίνουν καλύτερα αποτελέσματα.
			* Σχετικές πηγές: https://stackoverflow.com/questions/2624192/good-hash-function-for-strings
			* https://computinglife.wordpress.com/2008/11/20/why-do-hash-functions-use-prime-numbers/
		* Μέσω της συνάρτησης print_bucket_no_of_entries, παρατηρήσαμε ότι ο μέσος όρος entries/bucket ήταν λογικός, καθώς και ότι δεν υπήρχαν τρομερές αποκλίσεις από αυτών.

Η δομή που επιλέχθηκε για την δημιουργία των κλικών είναι στην πραγματικότητα τα disjoint sets. Δεν υπάρχει ξεχωριστή δομή από το hashmap: κάθε spec σε μία γραμμή
στα .csv files με label = 1 περνά από την hash_function, βρίσκουμε τον αντίστοιχο κόμβο στην λίστα του bucket, και επάνω σε έναν δείκτη σε αυτόν τον κόμβο κάνουμε
πράξεις disjoint sets ανάλογες με την υλοποίηση των ανοδικών δένδρων. Το πεδίο parent σε έναν list_node είναι αυτό που χρησιμοποιείται για την υλοποίηση της εύρεσης
ρίζας και της ένωσης συνόλων. 
Όμως, για επιτάχυνση της εκτύπωσης των αποτελεσμάτων κρατάμε μία λίστα με τους αντιπροσώπους των συνόλων/κλικών. Αυτή είναι η clique_list. Τα nodes της είναι
οι αντιπρόσωποι των disjoint sets/cliques και το πεδίο next_in_line ακολουθείται για τον καθέναν από αυτούς, σχηματίζοντας μία λίστα με όλους τους κόμβους που
ανήκουν στην κλίκα. Αυτό το πεδίο ανανεώνεται με κάθε ένωση συνόλων.

## Πως λειτουργεί το πρόγραμμά μας

Πρώτα, γίνεται το parsing του dataset X. Δημιουργείται το list_node, το tuplelist για κάθε αρχείο και ο κόμβος προστίθεται στον hashmap. 
Μετά, γίνεται το parsing του dataset W ή Υ, ανάλογα με το πιο έχει επιλεχθεί (περισσότερα για αυτό σύντομα). Σε κάθε γραμμή με label = 1, βρίσκουμε τους κόμβους
μέσα στο hashmap των left_spec, right_spec και κάνουμε ένωση των κλικών στις οποίες ανήκουν. Τέλος, εκτυπώνεται η λίστα με όλες τις κλίκες.

## Πως να τρέξετε το πρόγραμμά μας

Το path για τα dataset είναι defined, και πρέπει και τα 3 να βρίσκονται στον ίδιο φάκελο με τα .c αρχεία μας.

* Για να μεταγλωττίσετε το πρόγραμμα με σκοπό να τρέξει για το medium dataset,
	``` 
		make medium
	```

* Για να μεταγλωττίσετε το πρόγραμμα με σκοπό να τρέξει για το large dataset,
	```
		make large
	```
* Για να τρέξετε το πρόγραμμα με έξοδο στο stdout,
	```
		make run
	```
* Για να τρέξετε το πρόγραμμα με έξοδο στο αρχείο output.txt
	```
		make run_out_file
	```
## Unit testing

* Για τον parser του dataset X, δεν υπάρχει κάποιο διαθέσιμο unit test, ο έλεγχος για την ορθότητά του έγινε χειρωνακτικά μέσω αλλεπάλληλων εκτυπώσεων.

* Για το map και το info_list, το testing είναι trivial

* Για τις κλίκες, δοκιμάζεται:
	* Η δημιουργία μίας κλίκας από ορισμένα test_vectors
	* Η εισαγωγή και η διαγραφή από την λίστα των αντιπροσώπων κλικών (όταν δύο κλίκες συνενώνονται, η μεγαλύτερη 'απορροφά' την μικρότερη και έτσι ο αντιπρόσωπος αυτής αφαιρείται από την συνολική λίστα)
	* Η δημιουργία δύο κλικών από ορισμένα test_vectors 

* Για το parsing των csv αρχείων, γίνονται έλεγχοι ότι διαβάζονται όλες οι γραμμές (φτάνουμε στο EOF με ασφάλεια), καθώς και ότι ο αριθμός γραμμών με label = 1 είναι ο αναμενόμενος.

Για να τρέξετε όλα τα tests, αρκεί να τρέξετε: 

	```
		make run_all_tests
	```

 



